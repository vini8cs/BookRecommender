{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader #vai converter o texto em um formato que o Lang Chain possa trabalhar\n",
    "from langchain_text_splitters import CharacterTextSplitter #vai dividir o texto em diferentes chunks de caracteres (há diferentes formas de fazer isso. Vale à pena pesquisar)\n",
    "from langchain_openai import OpenAIEmbeddings #vai converter o texto em embeddings (vetores) que o Lang Chain possa trabalhar utilizando modelos do OpenAI\n",
    "from langchain_chroma import Chroma #vaii guardar os vectors em vectors databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos agora utilizar as chaves de API do OpenAI. Parta isso vamos utilizar a a biblioteca dotenv\n",
    "# com .env\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('books_cleaned.csv')\n",
    "display(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(books[\"tag_description\"])\n",
    "\n",
    "#A tag é uma ótima forma de indentificar o nome do livro após utilizar a descrição para treinar o modelo, pois o que vamos ter de retorno na busca de vetores \n",
    "# é a descrição com a tag do livro. Utilizar a descrição para filtrar pelo livro é muito devagar, por isso utilizar a tag é uma melhor opçção\n",
    "\n",
    "#vamos então extrair as descrições e as tags dos livros\n",
    "\n",
    "books[\"tag_description\"].to_csv(\"books_tag_description.csv\", index=False, sep = \"\\n\", header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextLoader(\"books_tag_description.csv\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=0, chunk_overlap = 0, separator = \"\\n\") #vamos utilizar chunk_size = 0 para garantir que ele vai fazer a separação baseado no separator \n",
    "# e não em chunks de caracteres e utilizar chunk_overlap = 0 para garantir que ele não vai haver overlap entre as descrições.\n",
    "documents = text_splitter.split_documents(raw_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checando abaixo percebe-se que funcionou corretamente a separação das descrições\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos agora criar os embeddings para cada descrição e salvá-los em um banco de dados de vetores\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "db_books = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=huggingface_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

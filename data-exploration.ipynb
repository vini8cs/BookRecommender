{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dylanjcastillo/7k-books-with-metadata\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "books = pd.read_csv(os.path.join(path, \"books.csv\"))\n",
    "display(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando os dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.heatmap(books.isna().transpose(), cbar=False, ax=ax)\n",
    "ax.set_title(\"Missing values in dataset\")\n",
    "plt.ylabel(\"Missing values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando novas variáveis\n",
    "import numpy as np\n",
    "\n",
    "books[\"missing_description\"] = np.where(books[\"description\"].isna(), 1, 0)\n",
    "books[\"age_of_book\"] = 2025 - books[\"published_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionamos nossas colunas de interesse\n",
    "\n",
    "columns_of_interest = [\"num_pages\", \"age_of_book\", \"missing_description\", \"average_rating\"]\n",
    "correlation_matrix = books[columns_of_interest].corr(method=\"spearman\") #bom quanto vc está lidando com dados discretos\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar_kws={\"label\": \"Correlation coefficient\"})\n",
    "heatmap.set_title(\"Correlation matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como a perda de descrição não tem correlação com nenhum outro atributo, podemos remover os livros sem descrição, assim como remover dados faltantes das outras variáveis\n",
    "\n",
    "#Primeiro checamos quanto perderíamos de dados se removessemos os livros sem description, num_pages, average_rating e published_year\n",
    "\n",
    "book_missing = books[(books[\"description\"].isna()) | (books[\"num_pages\"].isna()) | (books[\"average_rating\"].isna()) | (books[\"published_year\"].isna())]\n",
    "\n",
    "print(\"Percentage of data lost if we remove rows with missing values:\", (len(book_missing) / len(books)) * 100)\n",
    "#como o valor é baixo, podemos remover os dados faltantes\n",
    "\n",
    "books_filtered = books.dropna(subset=[\"description\", \"num_pages\", \"average_rating\", \"published_year\"])\n",
    "display(books_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como vamos recomendar os livros pela classificação, precisamos checar como esta a distribuição de  categories\t\n",
    "\n",
    "books_filtered[\"categories\"].value_counts().reset_index().sort_values(\"count\", ascending=False).head(40).set_index(\"categories\").plot(kind=\"bar\", figsize=(10, 6))\n",
    "\n",
    "# Percebemos que a distribuição não é normal e precisamos ver como vamos normalizar esses dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No dataframe, também percebe-se que na descrição, que também será utilizada pra treinar o modelo de LLM, temos muitos valores não informativos, com informações curtas ou sem utilidade\n",
    "\n",
    "#Vamos então filtrar pelo número de palavras:\n",
    "\n",
    "books_filtered[\"description_word_count\"] = books_filtered[\"description\"].str.split().str.len()\n",
    "\n",
    "#vamos ver num histograma com intervalos de 10 palavras\n",
    "\n",
    "books_filtered[\"description_word_count\"].hist(bins=range(0, 1000, 10), figsize=(10, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos checar o que são essas descrições de até 10 palavras\n",
    "\n",
    "books_filtered[books_filtered[\"description_word_count\"] < 10][\"description\"].head(10)\n",
    "\n",
    "#não são descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora até 20 palavras\n",
    "\n",
    "display(books_filtered[(books_filtered[\"description_word_count\"] <= 20) & (books_filtered[\"description_word_count\"] >= 10)][\"description\"].head(10))\n",
    "\n",
    "#Talvez não tenha como ver bem aqui, mas ainda não está muito descritivo, mas se baixa-se num csv daria para verificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora até 30 palavras\n",
    "\n",
    "display(books_filtered[(books_filtered[\"description_word_count\"] <= 30) & (books_filtered[\"description_word_count\"] >= 20)][\"description\"].head(10))\n",
    "\n",
    "#Agora sim, temos descrições mais descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aumentamos um pouco por garantia\n",
    "\n",
    "book_no_missing_words = books_filtered[books_filtered[\"description_word_count\"] >= 25]\n",
    "display(book_no_missing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos criar uma variável que junta o título com o subtítulo\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "book_no_missing_words[\"title_subtitle\"] = np.where(\n",
    "    book_no_missing_words[\"subtitle\"].isna(), \n",
    "    book_no_missing_words[\"title\"],\n",
    "    book_no_missing_words[[\"title\", \"subtitle\"]].astype(str).agg(\": \".join, axis=1)\n",
    "    )\n",
    "\n",
    "display(book_no_missing_words[[\"title_subtitle\"]].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos também conectar os tags com as descrições\n",
    "\n",
    "book_no_missing_words[\"tag_description\"] = book_no_missing_words[[\"isbn13\", \"description\"]].astype(str).agg(\" \".join, axis=1)\n",
    "display(book_no_missing_words[\"tag_description\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos descartar as colunas que não vamos usar\n",
    "\n",
    "display(book_no_missing_words.columns)\n",
    "\n",
    "(\n",
    "    book_no_missing_words\n",
    "        .drop(columns=[\"subtitle\", \"missing_description\", \"age_of_book\"])\n",
    "        .to_csv(\"books_cleaned.csv\", index=False)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
